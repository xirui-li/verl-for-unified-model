{"uuid": "ea3ac1a4-fb01-46a6-9736-f7eef3ea61c8", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2_5_VLForConditionalGeneration", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1753725076394222080, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "2e911dba-770e-4792-ae81-645d45b0f871", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2_5_VLForConditionalGeneration", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1753725601868870144, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "c37fb678-8dec-4190-8098-58cc11d6a35e", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2_5_VLForConditionalGeneration", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1753725851017370880, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "0840e364-462b-4ec5-9e0b-466031715cf1", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2_5_VLForConditionalGeneration", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1753726185605988096, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "d9b5f2d9-6b40-43c4-82d7-8984e692893a", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2_5_VLForConditionalGeneration", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1753766800714211072, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "b335877e-9aa3-44b2-b130-900801b1b27a", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2_5_VLForConditionalGeneration", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1753767555694972928, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "cbfbc2f7-4937-42b0-bca2-4319079dea29", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2_5_VLForConditionalGeneration", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1754251075350123008, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "669e229f-7005-4b82-ad14-33d8ccf4f0a1", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1754283567233938944, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "6f4b33e3-bd11-4832-809f-687e9893adf5", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1754284232485268224, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "0387bfda-6eb0-43d5-b52d-6b5c056d36c7", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1754285095057709056, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "cdbaeaa4-3f06-49b2-8377-3cde75e9d8c4", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1754285395156023040, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "c4d2180b-eddd-41b5-8617-cb3c1a5359b5", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1754285821504481024, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
{"uuid": "17d6c404-f4a0-4880-882c-6f699fb82795", "provider": "UNKNOWN", "num_cpu": 96, "cpu_type": "AMD EPYC 9474F 48-Core Processor", "cpu_family_model_stepping": "25,17,1", "total_memory": 1081885999104, "architecture": "x86_64", "platform": "Linux-5.15.0-130-generic-x86_64-with-glibc2.35", "cuda_runtime": "12.4", "gpu_count": 1, "gpu_type": "NVIDIA RTX 6000 Ada Generation", "gpu_memory_per_device": 50893553664, "env_var_json": "{\"VLLM_USE_MODELSCOPE\": false, \"VLLM_USE_TRITON_FLASH_ATTN\": true, \"VLLM_ATTENTION_BACKEND\": null, \"VLLM_USE_FLASHINFER_SAMPLER\": null, \"VLLM_PP_LAYER_PARTITION\": null, \"VLLM_USE_TRITON_AWQ\": false, \"VLLM_USE_V1\": true, \"VLLM_ENABLE_V1_MULTIPROCESSING\": false}", "model_architecture": "Qwen2ForCausalLM", "vllm_version": "0.8.5", "context": "ENGINE_CONTEXT", "log_time": 1754286191677987072, "source": "production", "dtype": "torch.bfloat16", "tensor_parallel_size": 2, "block_size": 16, "gpu_memory_utilization": 0.6, "quantization": null, "kv_cache_dtype": "auto", "enable_lora": false, "enable_prompt_adapter": false, "enable_prefix_caching": true, "enforce_eager": false, "disable_custom_all_reduce": true}
